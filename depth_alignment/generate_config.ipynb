{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get config scale for the config.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from scipy.interpolate import RegularGridInterpolator\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import json\n",
    "\n",
    "# Constants\n",
    "# DATA_DIR = 'scannet/scene0710_00'\n",
    "DATA_DIR = 'scannetpp/7eac902fd5'\n",
    "COLMAP_DIR = os.path.join(DATA_DIR, 'colmap/sparse/0')\n",
    "SENSOR_DEPTH_DIR = os.path.join(DATA_DIR, 'depth')\n",
    "CONFIG_FILENAME = 'config_new.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_colmap_camera_matrix(colmap_cameras_path):\n",
    "    with open(colmap_cameras_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        lines = [line.strip() for line in lines if not line.startswith('#')]    # Skip all lines that begin with # (comments)\n",
    "        # Extract image size\n",
    "        # 1 SIMPLE_PINHOLE 624 468 600.941 312 234\n",
    "        image_size = tuple(map(int, lines[0].split(' ')[2:4]))\n",
    "        # Extract the camera parameters\n",
    "        camera_params = lines[0].split(' ')[-3:]\n",
    "        # Extract the focal length and principal point\n",
    "        f, cx, cy = map(float, camera_params)\n",
    "        # Construct the camera matrix\n",
    "        K = np.array([[f, 0, cx], [0, f, cy], [0, 0, 1]])\n",
    "    return image_size, K\n",
    "\n",
    "def get_colmap_dict_points(colmap_points_path):\n",
    "    colmap_points_dict = {}\n",
    "    with open(colmap_points_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        lines = [line.strip() for line in lines if not line.startswith('#')]    # Skip all lines that begin with # (comments)\n",
    "        for line in lines:\n",
    "            line = line.strip().split()\n",
    "            # 3D point list with one line of data per point:\n",
    "            # POINT3D_ID, X, Y, Z, R, G, B, ERROR, TRACK[] as (IMAGE_ID, POINT2D_IDX)\n",
    "            point_id = int(line[0])\n",
    "            x = float(line[1])\n",
    "            y = float(line[2])\n",
    "            z = float(line[3])\n",
    "            r = int(line[4])\n",
    "            g = int(line[5])\n",
    "            b = int(line[6])\n",
    "            error = float(line[7])\n",
    "            track = line[8:]\n",
    "            for i in range(8, len(line), 2):\n",
    "                image_id = int(line[i])\n",
    "                point2d_idx = int(line[i + 1])\n",
    "                track.append((image_id, point2d_idx))\n",
    "            colmap_points_dict[point_id] = (x, y, z, r, g, b, error, track)\n",
    "    return colmap_points_dict\n",
    "\n",
    "def get_colmap_points(colmap_images_path, image_id):\n",
    "    # Read the images.txt file which has the following format:\n",
    "    #   IMAGE_ID, QW, QX, QY, QZ, TX, TY, TZ, CAMERA_ID, NAME\n",
    "    #   POINTS2D[] as (X, Y, POINT3D_ID)\n",
    "    with open(colmap_images_path) as f:\n",
    "        lines = f.readlines()\n",
    "        lines = [line.strip() for line in lines if not line.startswith('#')]    # Skip all lines that begin with # (comments)\n",
    "        # Find the line corresponding to the image_id\n",
    "        points_2d = []\n",
    "        points_3d_ids = []\n",
    "        q = None\n",
    "        t = None\n",
    "        for idx, line in enumerate(lines):\n",
    "            if str(line).endswith(str(image_id) + '.JPG'):\n",
    "                # Read the camera transformation\n",
    "                q = list(map(float, lines[idx].split(' ')[1:5]))\n",
    "                t = list(map(float, lines[idx].split(' ')[5:8]))\n",
    "                # lines[idx+1] contains the POINTS2D[] line\n",
    "                line_points = lines[idx+1].split(' ')\n",
    "                # Read three elements at a time\n",
    "                for i in range(0, len(line_points), 3):\n",
    "                    x, y, point_3d_id = line_points[i:i+3]\n",
    "                    if point_3d_id != '-1':\n",
    "                        points_2d.append((float(x), float(y)))\n",
    "                        points_3d_ids.append(int(point_3d_id))\n",
    "\n",
    "    return q, t, points_2d, points_3d_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def quaternion_to_rotation_matrix(q):\n",
    "    \"\"\"\n",
    "    Convert a quaternion into a 3x3 rotation matrix.\n",
    "    \"\"\"\n",
    "    qw, qx, qy, qz = q\n",
    "    R = np.array([\n",
    "        [1 - 2*qy**2 - 2*qz**2, 2*qx*qy - 2*qz*qw, 2*qx*qz + 2*qy*qw],\n",
    "        [2*qx*qy + 2*qz*qw, 1 - 2*qx**2 - 2*qz**2, 2*qy*qz - 2*qx*qw],\n",
    "        [2*qx*qz - 2*qy*qw, 2*qy*qz + 2*qx*qw, 1 - 2*qx**2 - 2*qy**2]\n",
    "    ])\n",
    "    return R\n",
    "\n",
    "def rotation_traslation_to_matrix(R, t):\n",
    "    \"\"\"\n",
    "    Convert a rotation matrix and a translation vector into a 4x4 transformation matrix.\n",
    "    \"\"\"\n",
    "    Tr = np.eye(4)\n",
    "    Tr[:3, :3] = R\n",
    "    Tr[:3, 3] = t\n",
    "    return Tr\n",
    "\n",
    "def transform_points(points_3d, Tr):\n",
    "    \"\"\"\n",
    "    Transform 3D points from world coordinates to camera coordinates.\n",
    "    \n",
    "    Parameters:\n",
    "    points_3d : ndarray of shape (n, 3)\n",
    "        The 3D points in world coordinates.\n",
    "    T : ndarray of shape (4, 4)\n",
    "        The transformation matrix from world to camera coordinates.\n",
    "    Returns:\n",
    "    points_3d_transformed : ndarray of shape (n, 3)\n",
    "        The transformed 3D points in camera coordinates.\n",
    "    \"\"\"\n",
    "    # Add a column of ones to the points_3d\n",
    "    points_3d_homogeneous = np.hstack([points_3d, np.ones((points_3d.shape[0], 1))])\n",
    "    # Transform the points\n",
    "    points_3d_transformed = (Tr @ points_3d_homogeneous.T).T[:, :3]\n",
    "    return points_3d_transformed\n",
    "\n",
    "def compute_depth(points_3d_transformed):\n",
    "    \"\"\"\n",
    "    Compute the depth values from the transformed 3D points.\n",
    "    \n",
    "    Parameters:\n",
    "    points_3d_transformed : ndarray of shape (n, 3)\n",
    "        The transformed 3D points in camera coordinates.\n",
    "    \n",
    "    Returns:\n",
    "    depths : ndarray of shape (n,)\n",
    "        The depth values (z-coordinates) of the transformed points.\n",
    "    \"\"\"\n",
    "    return points_3d_transformed[:, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_points(K, points_3d):\n",
    "    \"\"\"\n",
    "    Project 3D points onto the image plane using the intrinsic matrix K.\n",
    "    \n",
    "    Parameters:\n",
    "    K : ndarray of shape (3, 3)\n",
    "        The intrinsic matrix.\n",
    "    points_3d : ndarray of shape (n, 3)\n",
    "        The 3D points in camera coordinates.\n",
    "    \n",
    "    Returns:\n",
    "    points_2d : ndarray of shape (n, 2)\n",
    "        The projected 2D points on the image plane.\n",
    "    depths : ndarray of shape (n,)\n",
    "        The depth values (z-coordinates) of the transformed points.\n",
    "    \"\"\"\n",
    "    # Convert 3D points to homogeneous coordinates\n",
    "    # points_3d_h = np.hstack([points_3d, np.ones((points_3d.shape[0], 1))])\n",
    "    \n",
    "    # Project to 2D (homogeneous coordinates)\n",
    "    points_2d_h = (K @ points_3d.T).T\n",
    "    \n",
    "    # Convert to non-homogeneous coordinates\n",
    "    points_2d = points_2d_h[:, :2] / points_2d_h[:, 2:]\n",
    "    depths = points_3d[:, 2]  # Extract depth values (z-coordinates)\n",
    "    \n",
    "    return points_2d, depths\n",
    "\n",
    "def filter_points_in_image(points_2d, depths, image_width, image_height):\n",
    "    \"\"\"\n",
    "    Filter points to determine which ones lie within the camera plane.\n",
    "    \n",
    "    Parameters:\n",
    "    points_2d : ndarray of shape (n, 2)\n",
    "        The projected 2D points on the image plane.\n",
    "    depths : ndarray of shape (n,)\n",
    "        The depth values of the points.\n",
    "    image_width : int\n",
    "        The width of the image.\n",
    "    image_height : int\n",
    "        The height of the image.\n",
    "    \n",
    "    Returns:\n",
    "    mask : ndarray of shape (n,)\n",
    "        A boolean array indicating which points are within the image boundaries and in front of the camera.\n",
    "    \"\"\"\n",
    "    mask = (\n",
    "        (points_2d[:, 0] >= 0) & (points_2d[:, 0] < image_width) &  # x coordinates within image width\n",
    "        (points_2d[:, 1] >= 0) & (points_2d[:, 1] < image_height) &  # y coordinates within image height\n",
    "        (depths > 0)  # points in front of the camera\n",
    "    )\n",
    "    return mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_depth_completion_scaling_to_m(depth):\n",
    "    # convert from depth completion scaling to meter, that means map range 0 .. 1 to range 0 .. 16,38m\n",
    "    return depth * (2 ** 16 - 1) / 4000.\n",
    "\n",
    "def compute_rmse(prediction, target):\n",
    "    return torch.sqrt((prediction - target).pow(2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image:  DSC01382\n",
      "Max colmap depths: 13.304091228913187\n",
      "Max metric depths: 2.434\n",
      "NUM POINTS:  925\n",
      "\n",
      "Image:  DSC01550\n",
      "Max colmap depths: 10.301697996302547\n",
      "Max metric depths: 1.895\n",
      "NUM POINTS:  436\n",
      "\n",
      "Image:  DSC01342\n",
      "Max colmap depths: 8.498469144193656\n",
      "Max metric depths: 1.444\n",
      "NUM POINTS:  102\n",
      "\n",
      "Image:  DSC01542\n",
      "Max colmap depths: 10.892920136205415\n",
      "Max metric depths: 2.031\n",
      "NUM POINTS:  997\n",
      "\n",
      "Image:  DSC01350\n",
      "Max colmap depths: 13.241056859548555\n",
      "Max metric depths: 1.9\n",
      "NUM POINTS:  207\n",
      "\n",
      "Image:  DSC01478\n",
      "Max colmap depths: 12.891204914785547\n",
      "Max metric depths: 2.224\n",
      "NUM POINTS:  1630\n",
      "\n",
      "Image:  DSC01294\n",
      "Max colmap depths: 13.855130789950898\n",
      "Max metric depths: 2.039\n",
      "NUM POINTS:  203\n",
      "\n",
      "Image:  DSC01526\n",
      "Max colmap depths: 17.373540350219727\n",
      "Max metric depths: 2.24\n",
      "NUM POINTS:  352\n",
      "\n",
      "Image:  DSC01278\n",
      "Max colmap depths: 13.647001369905656\n",
      "Max metric depths: 2.371\n",
      "NUM POINTS:  1593\n",
      "\n",
      "Image:  DSC01318\n",
      "Max colmap depths: 13.560607445980224\n",
      "Max metric depths: 1.589\n",
      "NUM POINTS:  292\n",
      "\n",
      "Image:  DSC01286\n",
      "Max colmap depths: 18.251989945629198\n",
      "Max metric depths: 2.217\n",
      "NUM POINTS:  723\n",
      "\n",
      "Image:  DSC01326\n",
      "Max colmap depths: 11.162414168930171\n",
      "Max metric depths: 1.979\n",
      "NUM POINTS:  202\n",
      "\n",
      "Image:  DSC01534\n",
      "Max colmap depths: 11.538052214761851\n",
      "Max metric depths: 2.118\n",
      "NUM POINTS:  141\n",
      "\n",
      "Image:  DSC01470\n",
      "Max colmap depths: 7.059804672103342\n",
      "Max metric depths: 1.296\n",
      "NUM POINTS:  1118\n",
      "\n",
      "Image:  DSC01510\n",
      "Max colmap depths: 9.070820900408004\n",
      "Max metric depths: 1.568\n",
      "NUM POINTS:  150\n",
      "\n",
      "Image:  DSC01462\n",
      "Max colmap depths: 10.26009989422484\n",
      "Max metric depths: 1.857\n",
      "NUM POINTS:  2002\n",
      "\n",
      "Image:  DSC01502\n",
      "Max colmap depths: 8.174164048364752\n",
      "Max metric depths: 1.543\n",
      "NUM POINTS:  235\n",
      "\n",
      "Image:  DSC01566\n",
      "Max colmap depths: 9.155732375149364\n",
      "Max metric depths: 1.741\n",
      "NUM POINTS:  213\n",
      "\n",
      "Image:  DSC01406\n",
      "Max colmap depths: 11.526498764923826\n",
      "Max metric depths: 2.149\n",
      "NUM POINTS:  1076\n",
      "\n",
      "Image:  DSC01374\n",
      "Max colmap depths: 11.869955357247587\n",
      "Max metric depths: 2.158\n",
      "NUM POINTS:  1016\n",
      "\n",
      "Image:  DSC01438\n",
      "Max colmap depths: 5.985891859058252\n",
      "Max metric depths: 1.265\n",
      "NUM POINTS:  567\n",
      "\n",
      "Image:  DSC01558\n",
      "Max colmap depths: 4.34469766122925\n",
      "Max metric depths: 0.839\n",
      "NUM POINTS:  100\n",
      "\n",
      "Image:  DSC01414\n",
      "Max colmap depths: 7.916164758061986\n",
      "Max metric depths: 1.379\n",
      "NUM POINTS:  477\n",
      "\n",
      "Image:  DSC01366\n",
      "Max colmap depths: 14.021566285348431\n",
      "Max metric depths: 2.313\n",
      "NUM POINTS:  494\n",
      "\n",
      "Image:  DSC01358\n",
      "Max colmap depths: 16.629593054455036\n",
      "Max metric depths: 1.226\n",
      "NUM POINTS:  120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# barbara_depths = torch.load(os.path.join(DATA_DIR, 'depths.pth'))\n",
    "# Get camera matrix\n",
    "image_size, K = get_colmap_camera_matrix(os.path.join(COLMAP_DIR, 'cameras.txt'))\n",
    "image_width, image_height = image_size\n",
    "# Get dictionary of points\n",
    "points_dict = get_colmap_dict_points(os.path.join(COLMAP_DIR, 'points3D.txt'))\n",
    "ls_colmap_errors = []\n",
    "ls_colmap_depths = []\n",
    "ls_sensor_depths = []\n",
    "ls_sensor_depths_all = []\n",
    "\n",
    "# Iterate over the depths in the directory\n",
    "for filename in os.listdir(SENSOR_DEPTH_DIR):\n",
    "    #filename = os.path.basename(filename).split('.')[0] + '.npy'\n",
    "    image_id = filename.split('.')[0]\n",
    "    print('Image: ', image_id)\n",
    "    # Get points from COLMAP for the same image\n",
    "    colmap_images_path = os.path.join(COLMAP_DIR, 'images.txt')\n",
    "    q, t, _, points_3d_ids = get_colmap_points(colmap_images_path, image_id)\n",
    "    points_3d = [points_dict[point_id] for point_id in points_3d_ids]\n",
    "    # Select the first three elements of the points_3d\n",
    "    points_3d_xyz = np.array([point[:3] for point in points_3d])\n",
    "    points_error = np.array([point[6] for point in points_3d])\n",
    "    # Transform the 3D points into camera coordinates\n",
    "    Tr = rotation_traslation_to_matrix(quaternion_to_rotation_matrix(q), t)\n",
    "    if points_3d_xyz.shape[0] == 0:\n",
    "        print(f'NO POINTS FOR IMAGE {image_id}')\n",
    "        continue\n",
    "    points_3d_transformed = transform_points(np.array(points_3d_xyz)[:, :3], Tr)\n",
    "    # Sanity check. Project points and get depths\n",
    "    points_2d, colmap_depths = project_points(K, points_3d_transformed)\n",
    "    # Sanity check. Filter points within the image boundaries\n",
    "    mask = filter_points_in_image(points_2d, colmap_depths, image_width, image_height)\n",
    "    if mask.any() == False:\n",
    "        # This should never happen if the points from COLMAP are correct\n",
    "        print(f'WARNING, ALL COLMAP POINTS SHOULD LIE INSIDE THE IMAGE PLANE {image_id}')\n",
    "        continue\n",
    "    # Recover metric depth from sensor data\n",
    "    sensor_depth = np.array(Image.open(os.path.join(SENSOR_DEPTH_DIR, filename)), dtype=np.float64) / 1000.\n",
    "    # Get the depth values using indexes (round to the 2d positions to the closest integer)\n",
    "    points_2d = np.round(points_2d).astype(np.int32)\n",
    "    points_2d = points_2d[:, [1, 0]]    # Change (u, v) for (v, u) to match the sensor_depth (height, width)\n",
    "    # points_2d[:, 0] = points_2d[:, 0] - 6\n",
    "    # points_2d[:, 1] = points_2d[:, 1] - 8\n",
    "    # Check if out of bounds (the rgb images have already being cropped)\n",
    "    mask = (points_2d[:, 0] >= 0) & (points_2d[:, 1] >= 0) & (points_2d[:, 0] < sensor_depth.shape[0]) & (points_2d[:, 1] < sensor_depth.shape[1])\n",
    "    points_2d = points_2d[mask]\n",
    "    metric_depths = sensor_depth[points_2d[:, 0], points_2d[:, 1]]\n",
    "    mask_valid = metric_depths > 0\n",
    "    metric_depths = metric_depths[mask_valid]\n",
    "    \n",
    "    print('Max colmap depths:', colmap_depths.max())\n",
    "    if metric_depths.size > 0:\n",
    "        print('Max metric depths:', metric_depths.max())\n",
    "    print('NUM POINTS: ', metric_depths.size)\n",
    "    # Accumulate the depths and errors\n",
    "    ls_colmap_depths.extend(colmap_depths[mask][mask_valid])\n",
    "    ls_sensor_depths.extend(metric_depths)\n",
    "    ls_colmap_errors.extend(points_error[mask][mask_valid])\n",
    "    ls_sensor_depths_all.extend(sensor_depth)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean scale:  0.18446688255042698\n",
      "Max depth:  2.434\n"
     ]
    }
   ],
   "source": [
    "def compute_mean_scale(depths, errors, ground_truth_depths):\n",
    "    depths = np.array(depths).squeeze()\n",
    "    errors = np.array(errors).squeeze()\n",
    "    ground_truth_depths = np.array(ground_truth_depths).squeeze()\n",
    "    n = depths.shape[0]\n",
    "\n",
    "    # Compute the mean scale weighting using the inverse of the errors\n",
    "    weights = 1.0 / errors\n",
    "    #scale = np.sum(weights * ground_truth_depths / depths) / np.sum(weights)  # Small difference using weights\n",
    "    scale = np.mean(ground_truth_depths / depths)\n",
    "    return scale\n",
    "\n",
    "mean_scale = compute_mean_scale(ls_colmap_depths, ls_colmap_errors, ls_sensor_depths)\n",
    "\n",
    "print('Mean scale: ', mean_scale)\n",
    "print('Max depth: ', np.max(ls_sensor_depths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write config.json file\n",
    "config = {\n",
    "    'name': os.path.basename(DATA_DIR),\n",
    "    'max_depth': np.max([4.0, np.max(ls_sensor_depths)]),\n",
    "    'mean_scale': mean_scale,\n",
    "    \"rgb_only\": False\n",
    "}\n",
    "with open(os.path.join(DATA_DIR, CONFIG_FILENAME), 'w') as f:\n",
    "    json.dump(config, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_colmap_camera_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# \u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# barbara_depths = torch.load(os.path.join(DATA_DIR, 'depths.pth'))\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Get camera matrix\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m image_size, K \u001b[38;5;241m=\u001b[39m \u001b[43mget_colmap_camera_matrix\u001b[49m(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(COLMAP_DIR, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcameras.txt\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m      5\u001b[0m image_width, image_height \u001b[38;5;241m=\u001b[39m image_size\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Get dictionary of points\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_colmap_camera_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "# \n",
    "# barbara_depths = torch.load(os.path.join(DATA_DIR, 'depths.pth'))\n",
    "# Get camera matrix\n",
    "image_size, K = get_colmap_camera_matrix(os.path.join(COLMAP_DIR, 'cameras.txt'))\n",
    "image_width, image_height = image_size\n",
    "# Get dictionary of points\n",
    "points_dict = get_colmap_dict_points(os.path.join(COLMAP_DIR, 'points3D.txt'))\n",
    "ls_colmap_errors = []\n",
    "ls_colmap_depths = []\n",
    "ls_sensor_depths = []\n",
    "ls_sensor_depths_all = []\n",
    "\n",
    "# Iterate over the depths in the directory\n",
    "for filename in os.listdir(SENSOR_DEPTH_DIR):\n",
    "    #filename = os.path.basename(filename).split('.')[0] + '.npy'\n",
    "    image_id = filename.split('.')[0]\n",
    "    print('Image: ', image_id)\n",
    "    # Get points from COLMAP for the same image\n",
    "    colmap_images_path = os.path.join(COLMAP_DIR, 'images.txt')\n",
    "    q, t, _, points_3d_ids = get_colmap_points(colmap_images_path, image_id)\n",
    "    points_3d = [points_dict[point_id] for point_id in points_3d_ids]\n",
    "    # Select the first three elements of the points_3d\n",
    "    points_3d_xyz = np.array([point[:3] for point in points_3d])\n",
    "    points_error = np.array([point[6] for point in points_3d])\n",
    "    # Transform the 3D points into camera coordinates\n",
    "    Tr = rotation_traslation_to_matrix(quaternion_to_rotation_matrix(q), t)\n",
    "    if points_3d_xyz.shape[0] == 0:\n",
    "        print(f'NO POINTS FOR IMAGE {image_id}')\n",
    "        continue\n",
    "    points_3d_transformed = transform_points(np.array(points_3d_xyz)[:, :3], Tr)\n",
    "    # Sanity check. Project points and get depths\n",
    "    points_2d, colmap_depths = project_points(K, points_3d_transformed)\n",
    "    # Sanity check. Filter points within the image boundaries\n",
    "    mask = filter_points_in_image(points_2d, colmap_depths, image_width, image_height)\n",
    "    if mask.any() == False:\n",
    "        # This should never happen if the points from COLMAP are correct\n",
    "        print(f'WARNING, ALL COLMAP POINTS SHOULD LIE INSIDE THE IMAGE PLANE {image_id}')\n",
    "        continue\n",
    "    # Recover metric depth from sensor data\n",
    "    sensor_depth = np.array(Image.open(os.path.join(SENSOR_DEPTH_DIR, filename)), dtype=np.float64) / 1000.\n",
    "    # Get the depth values using indexes (round to the 2d positions to the closest integer)\n",
    "    points_2d = np.round(points_2d).astype(np.int32)\n",
    "    points_2d = points_2d[:, [1, 0]]    # Change (u, v) for (v, u) to match the sensor_depth (height, width)\n",
    "    # points_2d[:, 0] = points_2d[:, 0] - 6\n",
    "    # points_2d[:, 1] = points_2d[:, 1] - 8\n",
    "    # Check if out of bounds (the rgb images have already being cropped)\n",
    "    mask = (points_2d[:, 0] >= 0) & (points_2d[:, 1] >= 0) & (points_2d[:, 0] < sensor_depth.shape[0]) & (points_2d[:, 1] < sensor_depth.shape[1])\n",
    "    points_2d = points_2d[mask]\n",
    "    metric_depths = sensor_depth[points_2d[:, 0], points_2d[:, 1]]\n",
    "    mask_valid = metric_depths > 0\n",
    "    metric_depths = metric_depths[mask_valid]\n",
    "    \n",
    "    print('Max colmap depths:', colmap_depths.max())\n",
    "    if metric_depths.size > 0:\n",
    "        print('Max metric depths:', metric_depths.max())\n",
    "    print('NUM POINTS: ', metric_depths.size)\n",
    "    # Accumulate the depths and errors\n",
    "    ls_colmap_depths.extend(colmap_depths[mask][mask_valid])\n",
    "    ls_sensor_depths.extend(metric_depths)\n",
    "    ls_colmap_errors.extend(points_error[mask][mask_valid])\n",
    "    ls_sensor_depths_all.extend(sensor_depth)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adlr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
